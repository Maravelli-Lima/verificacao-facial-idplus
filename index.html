<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <title>IDPlus â€“ VerificaÃ§Ã£o Doc + Selfie</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body { font-family: Arial, sans-serif; text-align: center; margin-top: 30px; }
    #docImage, #videoElement, #selfieCanvas { max-width: 300px; margin-top: 10px; }
    #btnStart { margin-top: 10px; }
  </style>
</head>
<body>
  <h1>IDPlus â€“ VerificaÃ§Ã£o Doc + Selfie</h1>

  <p>ğŸ“„ Upload da foto do documento:
    <input type="file" id="docUpload" accept="image/*">
  </p>
  <img id="docImage" alt="Documento" />

  <div>
    <video id="videoElement" autoplay muted></video>
    <canvas id="selfieCanvas" style="display:none;"></canvas>
  </div>

  <button id="btnStart">ğŸ“¸ Capturar Selfie & Comparar</button>

  <p id="status"><strong>Status:</strong> aguardando upload do documento.</p>

  <script>
    const docUpload = document.getElementById('docUpload');
    const docImage = document.getElementById('docImage');
    const video = document.getElementById('videoElement');
    const canvas = document.getElementById('selfieCanvas');
    const btnStart = document.getElementById('btnStart');
    const statusText = document.getElementById('status');

    let docDescriptor = null;

    async function loadModels() {
      statusText.innerText = 'ğŸ”„ Carregando modelos...';
      const MODEL_URL = 'https://cdn.jsdelivr.net/npm/face-api.js/models';
      await Promise.all([
        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),
        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
        faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL)
      ]);
      statusText.innerText = 'âœ… Modelos carregados.';
    }

    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
    }

    docUpload.addEventListener('change', async () => {
      const file = docUpload.files[0];
      if (!file) return;

      const img = await faceapi.bufferToImage(file);
      docImage.src = img.src;
      statusText.innerText = 'ğŸ” Analisando documento...';

      const detection = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();
      if (!detection) {
        statusText.innerText = 'âŒ Nenhum rosto detectado no documento.';
        return;
      }
      docDescriptor = detection.descriptor;
      statusText.innerText = 'âœ… Documento analisado. Abra a cÃ¢mera e clique no botÃ£o para comparar.';
    });

    btnStart.addEventListener('click', async () => {
      if (!docDescriptor) {
        statusText.innerText = 'âš ï¸ Envie o documento primeiro.';
        return;
      }
      statusText.innerText = 'ğŸ“¸ Capturando selfie...';
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);

      const detection = await faceapi.detectSingleFace(canvas).withFaceLandmarks().withFaceDescriptor();
      if (!detection) {
        statusText.innerText = 'âŒ Nenhum rosto detectado na selfie.';
        return;
      }

      const distance = faceapi.euclideanDistance(docDescriptor, detection.descriptor);
      const similarity = (1 - distance) * 100;

      if (similarity > 60) {
        statusText.innerText = `âœ… Rosto compatÃ­vel! Similaridade: ${similarity.toFixed(2)}%`;
      } else {
        statusText.innerText = `âŒ Rosto diferente. Similaridade: ${similarity.toFixed(2)}%`;
      }
    });

    loadModels().then(startCamera);
  </script>
</body>
</html>
