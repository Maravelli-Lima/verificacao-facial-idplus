<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8" />
  <title>IDPlus ‚Äì Verifica√ß√£o Doc + Selfie</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 2em;
    }
    video, canvas, img {
      margin-top: 1em;
      max-width: 320px;
      height: auto;
    }
    #status {
      margin-top: 1em;
      font-weight: bold;
    }
  </style>
</head>
<body>
  <h1>IDPlus ‚Äì Verifica√ß√£o Doc + Selfie</h1>

  <!-- Upload do Documento -->
  <label for="docUpload">üìÑ Upload da foto do documento:</label>
  <input type="file" id="docUpload" accept="image/*" /><br />
  <img id="docImage" alt="Documento" />

  <!-- C√¢mera -->
  <div>
    <video id="videoElement" autoplay muted></video><br />
    <button id="btnStart">üì∑ Capturar Selfie & Comparar</button>
  </div>

  <div id="status">‚åõ Carregando modelos...</div>

  <script>
    const docUpload = document.getElementById('docUpload');
    const docImage = document.getElementById('docImage');
    const video = document.getElementById('videoElement');
    const btnStart = document.getElementById('btnStart');
    const statusDiv = document.getElementById('status');

    let docDescriptor = null;

    async function loadModels() {
      const MODEL_URL = 'https://cdn.jsdelivr.net/npm/face-api.js/models';
      await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
      await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
      await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
      statusDiv.textContent = '‚úÖ Modelos carregados. Pronto!';
    }

    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        statusDiv.textContent = 'üé• C√¢mera ativada.';
      } catch (err) {
        console.error('Erro ao acessar a c√¢mera:', err);
        statusDiv.textContent = '‚ùå N√£o foi poss√≠vel acessar a c√¢mera.';
      }
    }

    docUpload.addEventListener('change', async () => {
      const file = docUpload.files[0];
      if (!file) return;

      const img = await faceapi.bufferToImage(file);
      docImage.src = img.src;
      statusDiv.textContent = 'üß† Analisando documento...';

      const detections = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();
      if (!detections) {
        statusDiv.textContent = '‚ùå Nenhum rosto detectado no documento.';
        return;
      }

      docDescriptor = detections.descriptor;
      statusDiv.textContent = '‚úÖ Documento analisado. Pronto para selfie.';
    });

    btnStart.addEventListener('click', async () => {
      if (!docDescriptor) {
        statusDiv.textContent = '‚ö†Ô∏è Envie o documento primeiro.';
        return;
      }

      const capture = await faceapi.detectSingleFace(video).withFaceLandmarks().withFaceDescriptor();
      if (!capture) {
        statusDiv.textContent = '‚ùå Nenhum rosto detectado na selfie.';
        return;
      }

      const distance = faceapi.euclideanDistance(docDescriptor, capture.descriptor);
      const match = distance < 0.6;
      statusDiv.textContent = match
        ? `‚úÖ Verifica√ß√£o conclu√≠da. Similaridade alta (dist√¢ncia: ${distance.toFixed(4)})`
        : `‚ùå Rosto n√£o compat√≠vel (dist√¢ncia: ${distance.toFixed(4)})`;
    });

    // In√≠cio
    window.addEventListener('DOMContentLoaded', async () => {
      await loadModels();
      await startCamera();
    });
  </script>
</body>
</html>
